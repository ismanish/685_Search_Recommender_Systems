{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262ee4f1cc793d5cc0302d24cbc64461",
     "grade": false,
     "grade_id": "cell-aa820d6aaf4304db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf2f8489b1bdee32b8bcb32c7cf8f42",
     "grade": false,
     "grade_id": "cell-24e63ee011a83003",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Assignment 4: Collaborative Filtering (50 pts)\n",
    "\n",
    "Our newsfeed business eventually went bankrupt because we were unable to serve our subscribers' long-term information needs well using Adaptive Filtering. Back from a long trip, fully recharged, you take a freelance job as an external consultant for Steam, a software platform that sells video games. You learned during the trip that yet another way of making recommendations to users is through Collaborative Filtering, and your supervisor provided you with a [data set](https://cseweb.ucsd.edu/~jmcauley/datasets.html#steam_data) (\"Version 1: User and Item Data\") about many Steam users' time spent playing various games. You are confident about offering useful recommendations to users this time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af8ec04b478ec0e1485976401387cbee",
     "grade": false,
     "grade_id": "cell-02a587800a89d459",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The function below reads and processes the user-game data, and returns a [CSR](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) user-game matrix. The user-game matrix is very similar to the \"user-item matrix\" in the lecture slides, in that each row represents a user and each column represents a game (item). The `(i, j)` entry of the user-game matrix represents user `i`'s time spent playing game `j` measured in thousand hours, which we also call \"playtime\". Playtime is a natural proxy for a user's preference on games --- the more time a user spent playing a game, the more attractive the game is. To allow a qualitative analysis of the filtering results later, this function also returns a `list` containing the names of the games in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0045d1c003a8489b8a59b253b1177132",
     "grade": false,
     "grade_id": "cell-daadec1d4545f9d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def read_data(max_user=1000):\n",
    "    items_to_cols = dict()\n",
    "    data, indices, indptr = [], [], [0]\n",
    "\n",
    "    with gzip.open(\"assets/australian_users_items.json.gz\", \"rb\") as f:\n",
    "        user_count = 0\n",
    "        for line in f:\n",
    "            if max_user is not None and user_count >= max_user:\n",
    "                break\n",
    "\n",
    "            # Parse each line as a dict\n",
    "            user_dict = eval(line)\n",
    "            if not user_dict[\"items\"]:\n",
    "                continue\n",
    "            elif all((item[\"playtime_forever\"] == 0 for item in user_dict[\"items\"])):\n",
    "                continue\n",
    "\n",
    "            # Ref: last example from https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "            for item in user_dict[\"items\"]:\n",
    "                col = items_to_cols.setdefault(item[\"item_name\"], len(items_to_cols))\n",
    "                indices.append(col)\n",
    "                data.append(item[\"playtime_forever\"] / 1000)\n",
    "            indptr.append(len(indices))\n",
    "            user_count += 1\n",
    "            \n",
    "    user_game_mat = csr_matrix((data, indices, indptr), dtype=float)\n",
    "    games = list(items_to_cols.keys())\n",
    "    \n",
    "    return user_game_mat, games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of user-game matrix = 0.97%\n",
      "['Counter-Strike', 'Team Fortress Classic', 'Day of Defeat', 'Deathmatch Classic', 'Half-Life: Opposing Force']\n"
     ]
    }
   ],
   "source": [
    "# Load the user-game matrix and a list of games\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "# Compute the proportion of non-zero entries in the user-game matrix\n",
    "density = user_game_mat.count_nonzero() / (user_game_mat.shape[0] * user_game_mat.shape[1])\n",
    "\n",
    "print(f\"Density of user-game matrix = {density * 100:.2f}%\") # A very sparse matrix\n",
    "print(games[:5]) # Any games you are also playing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "309447d6ddd6d94d968a10814627ae33",
     "grade": false,
     "grade_id": "cell-d63bebc6fef0f0d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Memory-based Collaborative Filtering (20 pts)\n",
    "\n",
    "Let's first implement memory-based Collaborative Filtering. Complete the function below that takes in a user-game matrix `user_game_mat` as returned by `read_data` and a zero-based user index `user_idx`. It returns a `np.ndarray` (or a `np.matrix`) of shape `(1, user_game_mat.shape[1])` that represents the predicted playtime for each game for the user at `user_idx`. The algorithm is described in the lecture slide titled \"Memory-based Approach\". We will use **Cosine Similarity** as the similarity measure between two users based on their **raw ratings**. You do **not** need to exclude the user at `user_idx` when averaging the ratings $v_{ij}$ to compute $\\hat{v}_{aj}$, since we are interested in recommending games that are not currently being played by the user. \n",
    "\n",
    "**Hint:** Even though the algorithm only specifies how to predict a single rating score $r_{aj}$, a fully vectorised solution to this problem is possible. Many of the steps in the algorithm can be performed simultaneously for all users/games. The calculation of $\\hat{v}_{aj}$ can be simplified as a matrix operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7a377459bc98168fac272bedfbc4d07",
     "grade": false,
     "grade_id": "cell-876ee5c9fdc4f347",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "def do_memory_cf(matrix, user_index):\n",
    "    \n",
    "    if issparse(matrix):\n",
    "        matrix_dense = matrix.toarray()\n",
    "    else:\n",
    "        matrix_dense = matrix\n",
    "        \n",
    "    # Calculate the average playtime for each user\n",
    "    avg_playtime_per_user = np.mean(matrix_dense, axis=1)\n",
    "    \n",
    "    # Adjust user playtimes by subtracting the user's average playtime\n",
    "    adjusted_playtimes = matrix_dense - avg_playtime_per_user.reshape(-1, 1)\n",
    "    \n",
    "    # Extract the playtime vector for the target user\n",
    "    target_user_vector = matrix_dense[user_index, :].reshape(1, -1)\n",
    "    \n",
    "    # Compute the similarity of the target user to all users\n",
    "    similarity_scores = cosine_similarity(target_user_vector, matrix_dense).flatten()\n",
    "    \n",
    "    # Ensure adjusted_playtimes is aligned correctly for dot product\n",
    "    weighted_sum = similarity_scores.dot(adjusted_playtimes)\n",
    "    \n",
    "    # Normalize the weighted sum by the total similarity to get the prediction\n",
    "    prediction = weighted_sum / np.sum(similarity_scores)\n",
    "\n",
    "    # Adjust the prediction by adding back the mean playtime of the target user\n",
    "    final_prediction = prediction + avg_playtime_per_user[user_index]\n",
    "    \n",
    "    # Ensure the final prediction is shaped correctly as a 1xN array (where N is the number of games)\n",
    "    final_prediction = final_prediction.reshape(1, -1)\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c953168f8e993ad83f6714a049e37a3f",
     "grade": true,
     "grade_id": "cell-0d4fa6e6c10761ca",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "user_idx = 0 # This may vary in the hidden tests\n",
    "\n",
    "stu_pred_playtime = do_memory_cf(user_game_mat, user_idx)\n",
    "\n",
    "# Some sanity checks\n",
    "assert isinstance(stu_pred_playtime, np.ndarray), f\"Q1: Your function should return a np.ndarray. \"\n",
    "assert stu_pred_playtime.ndim == 2, f\"Q1: Your np.ndarray should be 2-dimensional. \"\n",
    "assert stu_pred_playtime.shape == (1, user_game_mat.shape[1]), f\"Q1: Your np.ndarray is of an incorrect shape. \"\n",
    "\n",
    "# Test it with only one user\n",
    "stu_pred_playtime = do_memory_cf(user_game_mat[0], 0)\n",
    "\n",
    "if not np.allclose(stu_pred_playtime, user_game_mat[0].todense(), atol=1e-4, rtol=1e-2):\n",
    "    raise AssertionError(f\"Q1: When there is only one user, the user's raw playtime should be returned. \")\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "del user_game_mat, games, user_idx, stu_pred_playtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c9898439456685595821acd25822df7",
     "grade": false,
     "grade_id": "cell-4b8c9836fa3a544a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We could do some qualitative analysis on the results of our memory-based Collaborative Filtering. For example, we can determine what *new* games should be recommended to a user and how the recommendations compare with the games that the user spent most of the time playing. Do the recommendations make sense? You may need to google each game a bit to understand what type of game it is. We encourage you to perform other kinds of analysis as you see fit, such as computing the RMSE between the true and predicted playtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 favourite games:\n",
      "['The Elder Scrolls V: Skyrim', 'Terraria', 'Saints Row: The Third', 'Portal 2', \"Deus Ex: Human Revolution - Director's Cut\"]\n",
      "\n",
      "Top 5 recommended games:\n",
      "['Fallout 3', 'Dishonored', \"Life Is Strange™ - Directors' Commentary - 3. Intentions\", \"Life Is Strange™ - Directors' Commentary - 5. A lively world\", \"Hunted: The Demon's Forge\"]\n",
      "\n",
      "RMSE = 20.65125916832172\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "user_idx, top_n = 1, 5\n",
    "\n",
    "# Top favourite games\n",
    "user_vec = user_game_mat[user_idx].toarray().flatten()\n",
    "cur_max_inds = np.argsort(-user_vec)\n",
    "cur_top_games = [games[i] for i in cur_max_inds[:top_n]]\n",
    "print(f\"Top {top_n} favourite games:\")\n",
    "print(cur_top_games)\n",
    "\n",
    "print()\n",
    "\n",
    "# Top recommended games\n",
    "stu_pred_playtime = do_memory_cf(user_game_mat, user_idx)\n",
    "stu_pred_playtime = np.asarray(stu_pred_playtime).flatten()\n",
    "rec_max_inds = np.argsort(-stu_pred_playtime[user_vec == 0]) # user_vec == 0 => games currently not played by the user\n",
    "rec_top_games = [games[i] for i in rec_max_inds[:top_n]]\n",
    "print(f\"Top {top_n} recommended games:\")\n",
    "print(rec_top_games)\n",
    "\n",
    "print()\n",
    "\n",
    "# RMSE between true & predicted playtime\n",
    "rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - stu_pred_playtime[user_vec != 0]) ** 2))\n",
    "print(f\"RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be9da69d5070401a4421deaeefb6808a",
     "grade": false,
     "grade_id": "cell-d77248f90f58ff08",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Matrix-based Collaborative Filtering (30 pts)\n",
    "\n",
    "Collaborative Filtering can also be done via factoring the user-game matrix, which we now explore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa14fa4d5dc9307f229c608886ad8f7d",
     "grade": false,
     "grade_id": "cell-86e928bb412fa37e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2a: SVD-based Collaborative Filtering (20 pts)\n",
    "\n",
    "The main idea behind SVD-based Collaborative Filtering is to approximate the sparse user-game matrix with a rank-$k$ matrix: $R \\approx U_{k}\\Sigma_{k}V_{k}^{T}$. $k$ is also referred to as the number of \"factors\" which are represented by the columns of $U_{k}$ or the rows of $V_{k}^{T}$. Complete the function below that takes in a `user_game_mat` and a `user_idx` as usual, and performs SVD-based Collaborative Filtering with `num_factors` and `random_state`. Likewise, it should return a `np.ndarray` (or a `np.matrix`) of shape `(1, user_game_mat.shape[1])` that represents the predicted playtime for each game for the user at `user_idx`.\n",
    "\n",
    "**Hint:** The idea of SVD-based Collaborative Filtering may look simple, but it may well take a while to figure out how to implement that with `sklearn` (unless you implement your own SVD). It might be useful to think about what *data* you have available, what *methods* are associated with `sklearn`'s SVD and what the *shapes* of your inputs to those methods should be. **The ideal solution uses just one line of code for making predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb0f332228ab15c93df0f905317058f7",
     "grade": false,
     "grade_id": "cell-bc86a5d5efaff137",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def do_svd_cf(user_game_mat, user_idx, num_factors, random_state=None):\n",
    "    \"\"\"\n",
    "    Do SVD-based collaborative filtering for user at user_idx\n",
    "    \"\"\"\n",
    "    svd = TruncatedSVD(n_components=num_factors, random_state=random_state)\n",
    "    user_game_matrix_reduced = svd.fit_transform(user_game_mat)\n",
    "    user_game_matrix_approx = np.dot(user_game_matrix_reduced, svd.components_)\n",
    "    \n",
    "    # Extract the predicted playtime for the specified user\n",
    "    pred_playtime = user_game_matrix_approx[user_idx, :].reshape(1, -1)\n",
    "    \n",
    "\n",
    "    return pred_playtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6595ead5932713576598fd1daf6dde67",
     "grade": true,
     "grade_id": "cell-727b52baf225ea11",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "# These won't change in the hidden tests\n",
    "num_factors, random_state = 100, 42\n",
    "\n",
    "user_idx = 0 # This may vary in the hidden tests\n",
    "\n",
    "stu_pred_playtime = do_svd_cf(user_game_mat, user_idx, num_factors, random_state)\n",
    "\n",
    "# Some sanity checks\n",
    "assert isinstance(stu_pred_playtime, np.ndarray), f\"Q2a: Your function should return a np.ndarray. \"\n",
    "assert stu_pred_playtime.ndim == 2, f\"Q2a: Your np.ndarray should be 2-dimensional. \"\n",
    "assert stu_pred_playtime.shape == (1, user_game_mat.shape[1]), f\"Q2a: Your np.ndarray is of an incorrect shape. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "del user_game_mat, games, user_idx, stu_pred_playtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b54d2ec98b94a7f783fcac15bbd7895b",
     "grade": false,
     "grade_id": "cell-c417a5578af66b15",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Of course, we could carry out the same qualitative analysis on the results of our SVD-based Collaborative Filtering and compute the RMSE between the true and predicted playtime. Do the recommendations make (more) sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 favourite games:\n",
      "['The Elder Scrolls V: Skyrim', 'Terraria', 'Saints Row: The Third', 'Portal 2', \"Deus Ex: Human Revolution - Director's Cut\"]\n",
      "\n",
      "Top 5 recommended games:\n",
      "[\"Assassin's Creed Liberation\", 'Darkest of Days', 'Call of Duty', 'Half-Life 2', 'Trine']\n",
      "\n",
      "RMSE = 7.902019281745345\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "user_idx, top_n = 1, 5\n",
    "num_factors, random_state = 100, 42\n",
    "\n",
    "# Top favourite games\n",
    "user_vec = user_game_mat[user_idx].toarray().flatten()\n",
    "cur_max_inds = np.argsort(-user_vec)\n",
    "cur_top_games = [games[i] for i in cur_max_inds[:top_n]]\n",
    "print(f\"Top {top_n} favourite games:\")\n",
    "print(cur_top_games)\n",
    "\n",
    "print()\n",
    "\n",
    "# Top recommended games\n",
    "stu_pred_playtime = do_svd_cf(user_game_mat, user_idx, num_factors, random_state)\n",
    "stu_pred_playtime = np.asarray(stu_pred_playtime).flatten()\n",
    "rec_max_inds = np.argsort(-stu_pred_playtime[user_vec == 0]) # user_vec == 0 => games currently not played by the user\n",
    "rec_top_games = [games[i] for i in rec_max_inds[:top_n]]\n",
    "print(f\"Top {top_n} recommended games:\")\n",
    "print(rec_top_games)\n",
    "\n",
    "print()\n",
    "\n",
    "# RMSE between true & predicted playtime\n",
    "rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - stu_pred_playtime[user_vec != 0]) ** 2))\n",
    "print(f\"RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f31cc13529874d287d0b28b968ac35a0",
     "grade": false,
     "grade_id": "cell-e6ceaa63110215aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2b: NMF-based Collaborative Filtering (10 pts)\n",
    "\n",
    "NMF offers yet another way of factoring the user-game matrix. Complete the function below for NMF-based Collaborative Filtering, which accepts the same inputs and produces the same output as your function in the last question. Use `init=\"nndsvd\"` for your `NMF`. \n",
    "\n",
    "**Hint:** If you have come through the challenge of implementing SVD-based Collaborative Filtering with `sklearn`, then this question should be a breeze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20645683a9cf5cfea98af15296be86a7",
     "grade": false,
     "grade_id": "cell-b56b6de27c546376",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def do_nmf_cf(user_game_mat, user_idx, num_factors, random_state=None):\n",
    "    \"\"\"\n",
    "    Do NMF-based collaborative filtering for user at user_idx\n",
    "    \"\"\"\n",
    "    nmf = NMF(n_components=num_factors, init='nndsvd', random_state=random_state)\n",
    "    W = nmf.fit_transform(user_game_mat)\n",
    "    H = nmf.components_\n",
    "    \n",
    "    # Reconstruct the matrix and extract predictions\n",
    "    user_game_matrix_approx = np.dot(W, H)\n",
    "    pred_playtime = user_game_matrix_approx[user_idx, :].reshape(1, -1)\n",
    "    \n",
    "\n",
    "    return pred_playtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d761853889260dbda299291ba037b188",
     "grade": true,
     "grade_id": "cell-ccdcf77d66562cbc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "# These won't change in the hidden tests\n",
    "num_factors, random_state = 100, 42\n",
    "\n",
    "user_idx = 0 # This may vary in the hidden tests\n",
    "\n",
    "stu_pred_playtime = do_nmf_cf(user_game_mat, user_idx, num_factors, random_state)\n",
    "\n",
    "# Some sanity checks\n",
    "assert isinstance(stu_pred_playtime, np.ndarray), f\"Q2b: Your function should return a np.ndarray. \"\n",
    "assert stu_pred_playtime.ndim == 2, f\"Q2b: Your np.ndarray should be 2-dimensional. \"\n",
    "assert stu_pred_playtime.shape == (1, user_game_mat.shape[1]), f\"Q2b: Your np.ndarray is of an incorrect shape. \"\n",
    "\n",
    "# Some hidden tests - may take a while\n",
    "\n",
    "del user_game_mat, games, user_idx, stu_pred_playtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca7eaeb4417a77c7f257375da44162ba",
     "grade": false,
     "grade_id": "cell-a1ff09e07d7c21dc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We could do the same qualitative analysis again but this time on the results of our NMF-based Collaborative Filtering. How do the recommendations compare with that from SVD-based Collaborative Filtering? Better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 favourite games:\n",
      "['The Elder Scrolls V: Skyrim', 'Terraria', 'Saints Row: The Third', 'Portal 2', \"Deus Ex: Human Revolution - Director's Cut\"]\n",
      "\n",
      "Top 5 recommended games:\n",
      "[\"Assassin's Creed Liberation\", 'WARP', 'Dragon Saga', 'Beat Hazard', 'Darkest of Days']\n",
      "\n",
      "RMSE = 8.490670969341032\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "\n",
    "user_game_mat, games = read_data()\n",
    "\n",
    "user_idx, top_n = 1, 5\n",
    "num_factors, random_state = 100, 42\n",
    "\n",
    "# Top favourite games\n",
    "user_vec = user_game_mat[user_idx].toarray().flatten()\n",
    "cur_max_inds = np.argsort(-user_vec)\n",
    "cur_top_games = [games[i] for i in cur_max_inds[:top_n]]\n",
    "print(f\"Top {top_n} favourite games:\")\n",
    "print(cur_top_games)\n",
    "\n",
    "print()\n",
    "\n",
    "# Top recommended games\n",
    "stu_pred_playtime = do_nmf_cf(user_game_mat, user_idx, num_factors, random_state)\n",
    "stu_pred_playtime = np.asarray(stu_pred_playtime).flatten()\n",
    "rec_max_inds = np.argsort(-stu_pred_playtime[user_vec == 0]) # user_vec == 0 => games currently not played by the user\n",
    "rec_top_games = [games[i] for i in rec_max_inds[:top_n]]\n",
    "print(f\"Top {top_n} recommended games:\")\n",
    "print(rec_top_games)\n",
    "\n",
    "print()\n",
    "\n",
    "# RMSE between true & predicted playtime\n",
    "rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - stu_pred_playtime[user_vec != 0]) ** 2))\n",
    "print(f\"RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db6820626cdc921f9b436c41b198ef0e",
     "grade": false,
     "grade_id": "cell-393742c112d380f2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## References for data used\n",
    "\n",
    "Kang, W.C., & McAuley, J. (2018). Self-Attentive Sequential Recommendation. In 2018 IEEE International Conference on Data Mining (ICDM) (pp. 197-206).\n",
    "\n",
    "Wan, M., & McAuley, J. (2018). Item Recommendation on Monotonic Behavior Chains. In Proceedings of the 12th ACM Conference on Recommender Systems (pp. 86–94). Association for Computing Machinery.\n",
    "\n",
    "Pathak, A., Gupta, K., & McAuley, J. (2017). Generating and Personalizing Bundle Recommendations on Steam. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 1073–1076). Association for Computing Machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
